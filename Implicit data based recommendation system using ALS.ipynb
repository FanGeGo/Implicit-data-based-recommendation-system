{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "According to a new report released by Nielsen Music, on average, Americans now spend just slightly more than 32 hours a week listening to music. This is a staggering 36% increase in 2 years and has been made possible due to the popularity of music streaming sites like Spotify, Pandora, Apple Music etc.    \n",
    "With such a tremendous growth in the music industry, it becomes crucial to deliver personalized music recommendation to the listeners. This piqued our curiosity to understand the process that goes behind the music recommendation engine and led us to work on this project.  \n",
    "\n",
    "lastfm is one of the oldest music streaming companies that started providing personalized recommendations to its listeners. Their website is a standing example of the amount of analytics that they are using on their data to extract insights. So we thought of doing the same with the open dataset that we have for lastfm users. Although this dataset is 10 years old, the algorithms and the methologies applied would still be relevant for the latest songs and albums."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we want to do?\n",
    "To build a recommendation engine that provides personalized recommendations to listeners based on their listening history and visualize the same using advanced visualization tools  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data:\n",
    "\n",
    "    The data is formatted one entry per line as follows (tab separated):\n",
    "\n",
    "    usersha1-artmbid-artname-plays.tsv:\n",
    "      user-mboxsha1 \\t musicbrainz-artist-id \\t artist-name \\t plays\n",
    "\n",
    "    usersha1-profile.tsv:\n",
    "      user-mboxsha1 \\t gender ('m'|'f'|empty) \\t age (int|empty) \\t country (str|empty) \\t signup (date|empty)\n",
    "\n",
    "Example:\n",
    "\n",
    "    usersha1-artmbid-artname-plays.tsv:\n",
    "      000063d3fe1cf2ba248b9e3c3f0334845a27a6bf    af8e4cc5-ef54-458d-a194-7b210acf638f    cannibal corpse    48\n",
    "      000063d3fe1cf2ba248b9e3c3f0334845a27a6bf    eaaee2c2-0851-43a2-84c8-0198135bc3a8    elis    31\n",
    "      ...\n",
    "\n",
    "    usersha1-profile.tsv\n",
    "      000063d3fe1cf2ba248b9e3c3f0334845a27a6bf    m    19    Mexico    Apr 28, 2008\n",
    "      \n",
    "For further details, please refer to the readme file in the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implicit vs Explicit data** \n",
    "\n",
    "Also, the data that we have is implicit data.  \n",
    "To elaborate, Explicit data is direct preference data from the customers like ratings, likes etc and is often used in collaborative recommendation systems whereas implicit data is the non direct preference data like number of views of a customer, number of times a customer listened to a song or the number of times a customer purchased a particular type of product. In general, we have more noise in implicit data and it takes more effort to make relevant recommendations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the required libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import implicit\n",
    "\n",
    "# Load the data\n",
    "raw_data = pd.read_table('usersha1-artmbid-artname-plays.tsv')\n",
    "raw_data = raw_data.drop(raw_data.columns[1], axis=1)\n",
    "raw_data.columns = ['user', 'artist', 'plays']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting the data for our analysis\n",
    "raw_data1 = raw_data[0:2000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of users in the data: 40913\n",
      "Total number of artists in the data: 110821\n"
     ]
    }
   ],
   "source": [
    "print('Total number of users in the data:',len(raw_data1['user'].unique()))\n",
    "print('Total number of artists in the data:',len(raw_data1['artist'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are about 204 nulls in the artist column. Lets drop the null rows from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN columns\n",
    "data = raw_data1.dropna()\n",
    "data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key links for the below code:  \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix  \n",
    "\n",
    "**Advantages of the CSR format:**\n",
    "* efficient arithmetic operations CSR + CSR, CSR * CSR, etc.\n",
    "* efficient row slicing\n",
    "* fast matrix vector products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to deal with implicit data?\n",
    "(You can skip this part if you want to look at the code)\n",
    "\n",
    "As we all know that there are 2 main recommendation system algorithms\n",
    "1. Content based approach\n",
    "2. Collaborative filtering approach  \n",
    "\n",
    "Collaborative filtering is an approach based on past user behavior without requiring the creation of explicit profiles like in content based approach. Historically, recommendation systems depended on more information rich explicit datasets like ratings and thumbs up/down indications. However, explicit feedback is not always avaialable and it becomes crucial to make use of the vast amount of implicit data like user transaction data, browsing data or user play data which indirectly reflect opinion through observing user behavior.   \n",
    "Also, it is important to note that once the user gives permission to access the usage data, there is no need to collect explicit data as we can use implicit data to make recommendations.  \n",
    "\n",
    "**Coming to our dataset**  \n",
    "There are some unique characteristics of implicit data that prevents the use of conventional algorithms that were successful for explicit data.Lets quickly look into those characteristics briefly.  \n",
    "1. No negative feedback:\n",
    "    In explicit dataset, the user explicitly gives the information about his/her likes or dislikes and any other user-item pairs that did not have the information are considered are missing data. But in case of implicit, we don't know for sure if the user did not like the movie or did not even know about the movie. Just conisdering the data with positive feedback will not capture the entire picture and will lead to incorrect conclusions. Hence there is a need to address missing data.  \n",
    "    \n",
    "2. Implicit data is noisy:\n",
    "    User might be passively watching a movie or listening to a song and this will constitute to noise as long as the model is concerned.  \n",
    "    \n",
    "3. Frequency might not always represent the true user opinion or vice versa  \n",
    "\n",
    "**Neightborhood models vs Latent factor models:**  \n",
    "user oriented approach or item-oriented approach in collaborative filtering are the traditional neighborhood models as they consider similarities between users or items while making a recommendation. Item-oriented approach became popular as they performed better than user-oriented approach in terms of accuracy and are easy interpretable as it is easy to say that 2 items are similar than to talk about 2 similar minded individuals.  \n",
    "\n",
    "Calculating similarties between items would be a realitively simple task when it comes to ratings data as we can use Pearson cofficient to do that. But when it comes to implicit datasets, it becomes a bit complicated as the scale of the frequencies of the metrics are different for different users and might mean different.\n",
    "\n",
    "This takes us to the latent factor models in which we use matrix factorization methods to uncover the hidden feature vectors for users and items. Refer to the original paper to gain a complete understanding of how this algorithm is being used for implict data. http://yifanhu.net/PUB/cf.pdf\n",
    "\n",
    "**Matrix factorization**  \n",
    "The main idea behind matrix factorization is that we estimate user matrix and item matrix from the original sparse matrix by minimizing the cost function that involces 2 important metrics  \n",
    "Preference : Binary metric that indicates if the customer has listened to the music at least  \n",
    "Confidence: Metric that indicates if the user likes the song  \n",
    "\n",
    "**Alternating least squares**  \n",
    "It becomes computationally expensive to optimize the cost function with stochastic gradient as the total combinations of users and items will easily reach billions in case of real world datasets. Hence, an alternative approach called Alternating least squares to perform the optimization of the cost function. In this approach, the optimal estimates for the user vector and item vectors are estimated in an alternating manner by keeping one matrix constant and finally arrives at the optimal solution. This is very clearly stated in the paper that was mentioned. For example, in a particular iteration, we will have user vector constant while optimizing for item vector.  \n",
    "\n",
    "This should give you enough information about the theory behind alternating least squares for implicit dataset if you have read the brief and the paper.  \n",
    "\n",
    "**Shout out for Ben frederickson**  \n",
    "Thanks to Ben Frederickson, the entire algorithm is available as a module called 'Implicit' in python and provides a much cleaner approach to get recommendations instead of writing it from scratch and the execution speed has been enhanced by implementing it in Cython. We have used the same while building this recommendation engine.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites \n",
    "If you are running this on your personal system, please make sure that you perform the following steps:  \n",
    "Before starting the analysis, make sure to download the implicit package  \n",
    "Run the following command on your command prompt  \n",
    "*conda install -c conda-forge implicit*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets move on to the execution part of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the numbers to categories to be used for creating the categorical codes to avoid using long hash keys \n",
    "data['user'] = data['user'].astype(\"category\")\n",
    "data['artist'] = data['artist'].astype(\"category\")\n",
    "\n",
    "#cat.codes creates a categorical id for the users and artists\n",
    "data['user_id'] = data['user'].cat.codes\n",
    "data['artist_id'] = data['artist'].cat.codes\n",
    "\n",
    "# The implicit library expects data as a item-user matrix so we\n",
    "# create two matrices, one for fitting the model (item-user) \n",
    "# and one for recommendations (user-item)\n",
    "\n",
    "sparse_item_user = sparse.csr_matrix((data['plays'].astype(float), (data['artist_id'], data['user_id'])))\n",
    "sparse_user_item = sparse.csr_matrix((data['plays'].astype(float), (data['user_id'], data['artist_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.95588936009682"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_size = sparse_user_item.shape[0]*sparse_user_item.shape[1] # Number of possible interactions in the matrix\n",
    "num_purchases = len(sparse_user_item.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_purchases/matrix_size))\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have very high sparsity in our data. This might not result in favorable results at the end. But one thing we can be sure of if finding similar artists using the above data. As we will be having enough for each artist based on the people that have listened to them. Recommendations to the users might be less than expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def make_train(ratings, pct_test = 0.2):\n",
    "    '''\n",
    "    This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n",
    "    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, \n",
    "    while the training set replaces the specified percentage of them with a zero in the original ratings matrix. \n",
    "    \n",
    "    parameters: \n",
    "    \n",
    "    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n",
    "    copy of the original set. This is in the form of a sparse csr_matrix. \n",
    "    \n",
    "    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the \n",
    "    training set for later comparison to the test set, which contains all of the original ratings. \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    training_set - The altered version of the original data with a certain percentage of the user-item pairs \n",
    "    that originally had interaction set back to zero.\n",
    "    \n",
    "    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n",
    "    compares with the actual interactions.\n",
    "    \n",
    "    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n",
    "    This will be necessary later when evaluating the performance via AUC.\n",
    "    '''\n",
    "    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
    "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "    \n",
    "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
    "    \n",
    "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of item,user index into list\n",
    "\n",
    "    \n",
    "    random.seed(0) # Set the random seed to zero for reproducibility\n",
    "    \n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of item-user pairs without replacement\n",
    "\n",
    "    item_inds = [index[0] for index in samples] # Get the item row indices\n",
    "\n",
    "    user_inds = [index[1] for index in samples] # Get the user column indices\n",
    "\n",
    "    \n",
    "    training_set[item_inds, user_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "    \n",
    "    return training_set, test_set, list(set(user_inds)) # Output the unique list of user columns that were altered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use the above function to create the training and test sets for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% of the data has been masked for this exercise\n",
    "product_train, product_test, product_users_altered = make_train(sparse_item_user, pct_test = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the recommendation system\n",
    "\n",
    "Here we will use the implicit package from python to build the recommendation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 40.0/40 [00:10<00:00,  3.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the als model and fit it using the sparse item-user matrix\n",
    "# Parameters that we have chosen\n",
    "# 1. factors = 20 -- Latent factors for user and item vectors\n",
    "# 2. iterations = 20 -- Number of iterations to use while fitting the data\n",
    "# 3. regularization = 0.1 -- regularization constant to be used in the cost function\n",
    "\n",
    "model = implicit.als.AlternatingLeastSquares(factors=20, regularization=0.1, iterations=40)\n",
    "\n",
    "# Calculate the confidence by multiplying it by our alpha value.(alpha value corresponds to the confidence metric \n",
    "# that we discussed earlier)\n",
    "\n",
    "alpha_val = 15\n",
    "data_conf = (product_train * alpha_val).astype('double')\n",
    "\n",
    "# We have used an alpha_val of 15 after performing some iterations with different alpha values\n",
    "#Fit the model\n",
    "model.fit(data_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian personalized ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step ,we will be creating extracting the item_vector matrix and user_vector matrix that we have created through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vecs = model.item_factors\n",
    "user_vecs = model.user_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Artist vector matrix :  (110820, 20)\n",
      "Shape of User vector matrix :  (40913, 20)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Artist vector matrix : ', item_vecs.shape)\n",
    "print('Shape of User vector matrix : ', user_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the recommendation system using AUC-ROC curve\n",
    "The function below will help in evaluating our recommendation system by calculating the AUC - ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pylab as plt\n",
    "def auc_score(predictions, test):\n",
    "    '''\n",
    "    This simple function will output the area under the curve using sklearn's metrics. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    - predictions: your prediction output\n",
    "    \n",
    "    - test: the actual target result you are comparing to\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    - AUC (area under the Receiver Operating Characterisic curve)\n",
    "    '''\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "    return metrics.auc(fpr, tpr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_auc(training_set, altered_users, predictions, test_set):\n",
    "    '''\n",
    "    This function will calculate the mean AUC by user for any user that had their user-item matrix altered. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - The training set resulting from make_train, where a certain percentage of the original\n",
    "    user/item interactions are reset to zero to hide them from the model \n",
    "    \n",
    "    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.\n",
    "    These should be stored in a list, with user vectors as item zero and item vectors as item one. \n",
    "    \n",
    "    altered_users - The indices of the users where at least one user/item pair was altered from make_train function\n",
    "    \n",
    "    test_set - The test set constucted earlier from make_train function\n",
    "    \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions\n",
    "    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n",
    "    '''\n",
    "    \n",
    "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
    "    popularity_auc = [] # To store popular AUC scores\n",
    "    pop_items = np.array(test_set.sum(axis = 1)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "    item_vecs = predictions[1]\n",
    "    for user in altered_users: # Iterate through each user that had an item altered\n",
    "        training_column = training_set[:,user].toarray().reshape(-1) # Get the training set column\n",
    "        zero_inds = np.where(training_column == 0) # Find where the interaction had not yet occurred\n",
    "        \n",
    "        # Get the predicted values based on our user/item vectors\n",
    "        user_vec = predictions[0][user,:]\n",
    "        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "        \n",
    "        # Get only the items that were originally zero\n",
    "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "        actual = test_set[:,user].toarray()[zero_inds,0].reshape(-1)\n",
    "        \n",
    "        # Select the binarized yes/no interaction pairs from the original full data\n",
    "        # that align with the same pairs in training \n",
    "        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
    "        \n",
    "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "        \n",
    "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "    # End users iteration\n",
    "    \n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
    "   # Return the mean AUC rounded to three decimal places for both test and popularity benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.962, 0.934)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mean_auc(product_train, product_users_altered,\n",
    "              [sparse.csr_matrix(user_vecs), sparse.csr_matrix(item_vecs.T)], product_test)\n",
    "# AUC for our recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are actually getting a better AUC in terms of prediction of artists for a user. But there are a couple of points that we need to consider there.\n",
    "1. By calculating AUC, we are actually not considering the rank of the recommendation. Although, we might be predicting that the artist, the artist the user has listened might not be present in the top 20 recommendations.  \n",
    "2. Because of the sparsity of the data, we can see that there will be a lot more True negatives than false positives effectively lowering the False positive rate. This also contributes to the increase in AUC.  \n",
    "\n",
    "Having said that, let's see how our model performs when it comes to identifying similar artists and making recommendations to the users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example for recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding similar artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>artist</th>\n",
       "      <th>plays</th>\n",
       "      <th>user_id</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>red hot chili peppers</td>\n",
       "      <td>691</td>\n",
       "      <td>0</td>\n",
       "      <td>80876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>000429493d9716b66b02180d208d09b5b89fbe64</td>\n",
       "      <td>red hot chili peppers</td>\n",
       "      <td>234</td>\n",
       "      <td>29</td>\n",
       "      <td>80876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>0007e26aafcfc0b6dcb87d7041583fbb7cced88a</td>\n",
       "      <td>red hot chili peppers</td>\n",
       "      <td>159</td>\n",
       "      <td>44</td>\n",
       "      <td>80876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284</th>\n",
       "      <td>000b0bb32f149504e1df3cce85b6bfd20cef3dd0</td>\n",
       "      <td>red hot chili peppers</td>\n",
       "      <td>46</td>\n",
       "      <td>68</td>\n",
       "      <td>80876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>000b2ee840cbda56e0f41c8f248c4fb7ee275db3</td>\n",
       "      <td>red hot chili peppers</td>\n",
       "      <td>87</td>\n",
       "      <td>69</td>\n",
       "      <td>80876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user                 artist  plays  \\\n",
       "4     00000c289a1829a808ac09c00daf10bc3c4e223b  red hot chili peppers    691   \n",
       "1422  000429493d9716b66b02180d208d09b5b89fbe64  red hot chili peppers    234   \n",
       "2139  0007e26aafcfc0b6dcb87d7041583fbb7cced88a  red hot chili peppers    159   \n",
       "3284  000b0bb32f149504e1df3cce85b6bfd20cef3dd0  red hot chili peppers     46   \n",
       "3322  000b2ee840cbda56e0f41c8f248c4fb7ee275db3  red hot chili peppers     87   \n",
       "\n",
       "      user_id  artist_id  \n",
       "4           0      80876  \n",
       "1422       29      80876  \n",
       "2139       44      80876  \n",
       "3284       68      80876  \n",
       "3322       69      80876  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets start with red hot chilli peppers. Earlier in our exploration, we have seen that artist_id for red hot chilli peppers\n",
    "# is 220128\n",
    "data[data['artist'] == 'red hot chili peppers'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akhil\\Anaconda2\\envs\\py36\\lib\\site-packages\\numpy\\linalg\\linalg.py:2390: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red hot chili peppers\n",
      "muse\n",
      "nirvana\n",
      "placebo\n",
      "coldplay\n",
      "the beatles\n",
      "pink floyd\n",
      "foo fighters\n",
      "the killers\n",
      "nine inch nails\n"
     ]
    }
   ],
   "source": [
    "# Find the 10 most similar to red hot chilli peppers\n",
    "artist_id = 80876\n",
    "n_similar = 10 # getting the top ten similar items\n",
    "\n",
    "# Use implicit to get similar items.\n",
    "similar = model.similar_items(artist_id, n_similar)\n",
    "# Print the names of our most similar artists\n",
    "for artist in similar:\n",
    "    idx, score = artist\n",
    "    print (data.artist.loc[data.artist_id == idx].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar way, lets look atsome other band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>artist</th>\n",
       "      <th>plays</th>\n",
       "      <th>user_id</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>die Ärzte</td>\n",
       "      <td>1099</td>\n",
       "      <td>0</td>\n",
       "      <td>30264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>000a1585c5f65532a9c9187a882892982d345a5c</td>\n",
       "      <td>die Ärzte</td>\n",
       "      <td>148</td>\n",
       "      <td>61</td>\n",
       "      <td>30264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>000cb6427411006fe9a6193d3c4f59efed53fbef</td>\n",
       "      <td>die Ärzte</td>\n",
       "      <td>7</td>\n",
       "      <td>78</td>\n",
       "      <td>30264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6295</th>\n",
       "      <td>0014ffc91d3a5b59cce9bceaf22ef0d72e5711b8</td>\n",
       "      <td>die Ärzte</td>\n",
       "      <td>88</td>\n",
       "      <td>128</td>\n",
       "      <td>30264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13513</th>\n",
       "      <td>003059a886782e4d7936da913d3f064f637d0b2b</td>\n",
       "      <td>die Ärzte</td>\n",
       "      <td>5</td>\n",
       "      <td>274</td>\n",
       "      <td>30264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user     artist  plays  user_id  \\\n",
       "0      00000c289a1829a808ac09c00daf10bc3c4e223b  die Ärzte   1099        0   \n",
       "2943   000a1585c5f65532a9c9187a882892982d345a5c  die Ärzte    148       61   \n",
       "3787   000cb6427411006fe9a6193d3c4f59efed53fbef  die Ärzte      7       78   \n",
       "6295   0014ffc91d3a5b59cce9bceaf22ef0d72e5711b8  die Ärzte     88      128   \n",
       "13513  003059a886782e4d7936da913d3f064f637d0b2b  die Ärzte      5      274   \n",
       "\n",
       "       artist_id  \n",
       "0          30264  \n",
       "2943       30264  \n",
       "3787       30264  \n",
       "6295       30264  \n",
       "13513      30264  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['artist'] == 'die Ärzte'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "die Ärzte\n",
      "ska-p\n",
      "guano apes\n",
      "no doubt\n",
      "3 doors down\n",
      "mando diao\n",
      "amy macdonald\n",
      "nickelback\n",
      "bon jovi\n",
      "bloodhound gang\n"
     ]
    }
   ],
   "source": [
    "# Find the 10 most similar to red hot chilli peppers\n",
    "artist_id = 30264\n",
    "n_similar = 10 # getting the top ten similar items\n",
    "\n",
    "# Use implicit to get similar items.\n",
    "similar = model.similar_items(artist_id, n_similar)\n",
    "# Print the names of our most similar artists\n",
    "for artist in similar:\n",
    "    idx, score = artist\n",
    "    print (data.artist.loc[data.artist_id == idx].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights:\n",
    "* Also, one more example that we took was die Ärzte(90933). It is a punk rock from Berlin according to wiki   https://en.wikipedia.org/wiki/Die_%C3%84rzte  \n",
    "* The top recommendations for their music are die toten hosen(another german punk rock), blink-182(punk rock).  \n",
    "\n",
    "\n",
    "**It's really amazing how math works. Without mentioning any other features, the algorithm figured out the features vectors for each artist based on the number of times the users played their songs.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating user recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the users who have rock music on the top of their list by doing a simple EDA and find the recommendations for those users using the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rank'] = data.groupby(['user_id'])['plays'].rank(ascending = False)\n",
    "\n",
    "# filtering for their first choice\n",
    "data_1  = data[data['rank'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>artist</th>\n",
       "      <th>plays</th>\n",
       "      <th>user_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>die Ärzte</td>\n",
       "      <td>1099</td>\n",
       "      <td>0</td>\n",
       "      <td>30264</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25686</th>\n",
       "      <td>005d521c9f8b1acfc13b7a4cc4b39085edfc786a</td>\n",
       "      <td>die Ärzte</td>\n",
       "      <td>933</td>\n",
       "      <td>523</td>\n",
       "      <td>30264</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112</th>\n",
       "      <td>006aaaaf386fdbb0aea3f2bf9019e346a7294b6a</td>\n",
       "      <td>die Ärzte</td>\n",
       "      <td>946</td>\n",
       "      <td>595</td>\n",
       "      <td>30264</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30440</th>\n",
       "      <td>006f93b4213be13020a3819e0d0a86dcf97b58de</td>\n",
       "      <td>die Ärzte</td>\n",
       "      <td>1375</td>\n",
       "      <td>622</td>\n",
       "      <td>30264</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>00c465e5b33365ab91cc5cf161590a38044954af</td>\n",
       "      <td>die Ärzte</td>\n",
       "      <td>2924</td>\n",
       "      <td>1094</td>\n",
       "      <td>30264</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user     artist  plays  user_id  \\\n",
       "0      00000c289a1829a808ac09c00daf10bc3c4e223b  die Ärzte   1099        0   \n",
       "25686  005d521c9f8b1acfc13b7a4cc4b39085edfc786a  die Ärzte    933      523   \n",
       "29112  006aaaaf386fdbb0aea3f2bf9019e346a7294b6a  die Ärzte    946      595   \n",
       "30440  006f93b4213be13020a3819e0d0a86dcf97b58de  die Ärzte   1375      622   \n",
       "53937  00c465e5b33365ab91cc5cf161590a38044954af  die Ärzte   2924     1094   \n",
       "\n",
       "       artist_id  rank  \n",
       "0          30264   1.0  \n",
       "25686      30264   1.0  \n",
       "29112      30264   1.0  \n",
       "30440      30264   1.0  \n",
       "53937      30264   1.0  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Users with red hot chilli peppers as their first choice\n",
    "data_1[data_1['artist_id'] == 30264].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>artist</th>\n",
       "      <th>plays</th>\n",
       "      <th>user_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>00c465e5b33365ab91cc5cf161590a38044954af</td>\n",
       "      <td>die Ärzte</td>\n",
       "      <td>2924</td>\n",
       "      <td>1094</td>\n",
       "      <td>30264</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>00c465e5b33365ab91cc5cf161590a38044954af</td>\n",
       "      <td>equilibrium</td>\n",
       "      <td>1936</td>\n",
       "      <td>1094</td>\n",
       "      <td>36491</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>00c465e5b33365ab91cc5cf161590a38044954af</td>\n",
       "      <td>ensiferum</td>\n",
       "      <td>1782</td>\n",
       "      <td>1094</td>\n",
       "      <td>36343</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53940</th>\n",
       "      <td>00c465e5b33365ab91cc5cf161590a38044954af</td>\n",
       "      <td>system of a down</td>\n",
       "      <td>1167</td>\n",
       "      <td>1094</td>\n",
       "      <td>92524</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53941</th>\n",
       "      <td>00c465e5b33365ab91cc5cf161590a38044954af</td>\n",
       "      <td>sdp</td>\n",
       "      <td>1042</td>\n",
       "      <td>1094</td>\n",
       "      <td>85406</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53942</th>\n",
       "      <td>00c465e5b33365ab91cc5cf161590a38044954af</td>\n",
       "      <td>deichkind</td>\n",
       "      <td>1013</td>\n",
       "      <td>1094</td>\n",
       "      <td>29016</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53943</th>\n",
       "      <td>00c465e5b33365ab91cc5cf161590a38044954af</td>\n",
       "      <td>knorkator</td>\n",
       "      <td>920</td>\n",
       "      <td>1094</td>\n",
       "      <td>57157</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53944</th>\n",
       "      <td>00c465e5b33365ab91cc5cf161590a38044954af</td>\n",
       "      <td>typ:t.u.r.b.o.</td>\n",
       "      <td>911</td>\n",
       "      <td>1094</td>\n",
       "      <td>103029</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53945</th>\n",
       "      <td>00c465e5b33365ab91cc5cf161590a38044954af</td>\n",
       "      <td>serj tankian</td>\n",
       "      <td>813</td>\n",
       "      <td>1094</td>\n",
       "      <td>85997</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53946</th>\n",
       "      <td>00c465e5b33365ab91cc5cf161590a38044954af</td>\n",
       "      <td>rise against</td>\n",
       "      <td>779</td>\n",
       "      <td>1094</td>\n",
       "      <td>82040</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user            artist  plays  \\\n",
       "53937  00c465e5b33365ab91cc5cf161590a38044954af         die Ärzte   2924   \n",
       "53938  00c465e5b33365ab91cc5cf161590a38044954af       equilibrium   1936   \n",
       "53939  00c465e5b33365ab91cc5cf161590a38044954af         ensiferum   1782   \n",
       "53940  00c465e5b33365ab91cc5cf161590a38044954af  system of a down   1167   \n",
       "53941  00c465e5b33365ab91cc5cf161590a38044954af               sdp   1042   \n",
       "53942  00c465e5b33365ab91cc5cf161590a38044954af         deichkind   1013   \n",
       "53943  00c465e5b33365ab91cc5cf161590a38044954af         knorkator    920   \n",
       "53944  00c465e5b33365ab91cc5cf161590a38044954af    typ:t.u.r.b.o.    911   \n",
       "53945  00c465e5b33365ab91cc5cf161590a38044954af      serj tankian    813   \n",
       "53946  00c465e5b33365ab91cc5cf161590a38044954af      rise against    779   \n",
       "\n",
       "       user_id  artist_id  rank  \n",
       "53937     1094      30264   1.0  \n",
       "53938     1094      36491   2.0  \n",
       "53939     1094      36343   3.0  \n",
       "53940     1094      92524   4.0  \n",
       "53941     1094      85406   5.0  \n",
       "53942     1094      29016   6.0  \n",
       "53943     1094      57157   7.0  \n",
       "53944     1094     103029   8.0  \n",
       "53945     1094      85997   9.0  \n",
       "53946     1094      82040  10.0  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['user_id'] == 1094].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               artist     score\n",
      "0               lafee  1.328061\n",
      "1                 ost  1.282044\n",
      "2      disco ensemble  1.216249\n",
      "3          eisbrecher  1.200554\n",
      "4                4lyn  1.199269\n",
      "5       jan hegenberg  1.195768\n",
      "6   blood stain child  1.182727\n",
      "7         eläkeläiset  1.181833\n",
      "8           krypteria  1.167898\n",
      "9        freedom call  1.163600\n",
      "10        celldweller  1.161240\n",
      "11    sonic syndicate  1.155655\n",
      "12       revolverheld  1.153287\n",
      "13        dieter nuhr  1.149378\n",
      "14          fightstar  1.147582\n",
      "15      powerman 5000  1.146510\n",
      "16      stephen lynch  1.144552\n",
      "17            volbeat  1.143474\n",
      "18   disarmonia mundi  1.138794\n",
      "19              blind  1.137219\n"
     ]
    }
   ],
   "source": [
    "# Create recommendations for user with id 1246\n",
    "user_id = 1094\n",
    "\n",
    "# Use the implicit recommender.\n",
    "recommended = model.recommend(user_id, sparse_user_item,N = 20,filter_already_liked_items = False)\n",
    "\n",
    "artists = []\n",
    "scores = []\n",
    "\n",
    "# Get artist names from ids\n",
    "for item in recommended:\n",
    "    idx, score = item\n",
    "    artists.append(data.artist.loc[data.artist_id == idx].iloc[0])\n",
    "    scores.append(score)\n",
    "\n",
    "# Create a dataframe of artist names and scores\n",
    "recommendations = pd.DataFrame({'artist': artists, 'score': scores})\n",
    "\n",
    "print (recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe, although the model is not exactly recommending there top 10 again, the recommendations are still closer to what they have listened to. In this case, German music and punk bands.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:  \n",
    "\n",
    "We can still use the similar artists part of this model to make suggestions to the users based on the artists that they like.This will still provide an improvement experience to the users.  \n",
    "\n",
    "For the exact personalized recommendations to users, there are some key tasks that we need to perform to improve the result.\n",
    "1. Find a work around to deal with the sparsity of the data  \n",
    "2. Bring in the profile data and search data of the users to overlay on top of the recommendations to create an ensembled result  \n",
    "3. Apply more sophisticated algorithms like Bayesian personalied ranking that takes the ranking into consideration while making recommendations.  \n",
    "4. Use Factorization machines to deal with the sparsity of the data  \n",
    "5. Final use deep learning techniques to find similarities between the music in itself and overlay those results on to the collaborative filtering recommendations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "1. https://implicit.readthedocs.io/en/latest/als.html  \n",
    "2. https://jessesw.com/Rec-System/  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
